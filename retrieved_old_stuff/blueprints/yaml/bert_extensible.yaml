name: "bert_extensible"
description: "BERT transformer model with extensible design space definition for DSE research"
architecture: "transformer"

# Current build steps (unchanged from original BERT blueprint)
build_steps:
  # Cleanup and custom graph surgery
  - "common.cleanup"
  - "transformer.remove_head"
  - "transformer.remove_tail"
  - "transformer.qonnx_to_finn"
  
  # Reference IO generation and streamlining
  - "transformer.generate_reference_io"
  - "transformer.streamlining"
  - "transformer.infer_hardware"
  
  # FINN build steps (direct imports)
  - "step_create_dataflow_partition"
  - "step_specialize_layers"
  - "step_target_fps_parallelization"
  - "step_apply_folding_config"
  - "transformer.constrain_folding_and_set_pumped_compute"
  - "step_minimize_bit_width"
  - "step_generate_estimate_reports"
  - "step_hw_codegen"
  - "step_hw_ipgen"
  - "step_measure_rtlsim_performance"
  - "step_set_fifo_depths"
  - "step_create_stitched_ip"
  
  # Final metadata extraction
  - "transformer.shell_metadata_handover"

# Traditional parameters (backward compatibility)
parameters:
  model_type: "bert"
  precision: "int8"

# Enhanced design space definition for DSE research
design_space:
  dimensions:
    # Platform selection
    platform:
      type: "categorical"
      values: ["V80", "ZCU104", "U250"]
      default: "V80"
      description: "Target FPGA platform"
    
    # Performance parameters
    target_fps:
      type: "integer"
      range: [1000, 10000]
      default: 3000
      description: "Target frames per second (inferences/sec)"
    
    # Clock configuration
    clk_period_ns:
      type: "continuous"
      range: [2.0, 10.0]
      default: 3.33
      description: "Clock period in nanoseconds (affects max frequency)"
    
    # Memory and parallelization
    fifo_depth_strategy:
      type: "categorical"
      values: ["auto", "conservative", "aggressive"]
      default: "auto"
      description: "FIFO depth optimization strategy"
    
    # Precision and quantization
    weight_precision:
      type: "categorical"
      values: ["int4", "int8", "int16"]
      default: "int8"
      description: "Weight quantization precision"
    
    activation_precision:
      type: "categorical"
      values: ["int4", "int8", "int16"]
      default: "int8"
      description: "Activation quantization precision"
    
    # Folding configuration
    folding_optimization:
      type: "categorical"
      values: ["manual", "auto", "template"]
      default: "auto"
      description: "Folding configuration strategy"
    
    # Resource allocation preferences
    prefer_dsp_for_mult:
      type: "boolean"
      default: true
      description: "Prefer DSP blocks for multiplication operations"
    
    prefer_lut_for_small_mult:
      type: "boolean"
      default: false
      description: "Use LUTs for small multiplications"

  # Placeholder configurations for future FINN four-hook architecture
  finn_hooks_config:
    model_ops:
      # Model Operations Hook placeholder
      custom_ops_enabled:
        type: "boolean"
        default: false
        description: "Enable custom operator implementations"
      
      frontend_optimizations:
        type: "categorical"
        values: ["conservative", "standard", "aggressive"]
        default: "standard"
        description: "Frontend optimization level"
      
      op_fusion_level:
        type: "integer"
        range: [0, 3]
        default: 2
        description: "Operator fusion aggressiveness (0=none, 3=max)"
    
    model_transforms:
      # Model Transforms Hook placeholder
      streamlining_strategy:
        type: "categorical"
        values: ["minimal", "balanced", "aggressive"]
        default: "balanced"
        description: "Model streamlining approach"
      
      optimization_passes:
        type: "integer"
        range: [1, 10]
        default: 3
        description: "Number of optimization passes"
      
      constant_folding:
        type: "boolean"
        default: true
        description: "Enable constant folding optimizations"
    
    hw_kernels:
      # HW Kernels Hook placeholder
      kernel_preference:
        type: "categorical"
        values: ["rtl", "hls", "mixed"]
        default: "mixed"
        description: "Hardware kernel implementation preference"
      
      use_custom_kernels:
        type: "boolean"
        default: false
        description: "Enable custom kernel implementations"
      
      kernel_optimization_level:
        type: "categorical"
        values: ["area", "speed", "balanced"]
        default: "balanced"
        description: "Kernel optimization objective"
    
    hw_optimization:
      # HW Optimization Hook placeholder
      optimization_time_budget:
        type: "integer"
        range: [60, 3600]
        default: 300
        description: "Time budget for optimization in seconds"
      
      optimization_algorithm:
        type: "categorical"
        values: ["greedy", "simulated_annealing", "genetic"]
        default: "greedy"
        description: "Optimization algorithm for parameter tuning"
      
      parallel_exploration:
        type: "boolean"
        default: false
        description: "Enable parallel design point exploration"

# Constraint definitions for design space validation
constraints:
  # Hard constraints (must be satisfied)
  hard_constraints:
    max_lut_utilization: 0.85
    max_dsp_utilization: 0.85
    max_bram_utilization: 0.85
    min_clock_period_ns: 2.0
    max_target_fps: 10000
  
  # Soft constraints (preferences with penalties)
  soft_constraints:
    preferred_lut_utilization: 0.70
    preferred_dsp_utilization: 0.70
    preferred_power_w: 50.0
  
  # Custom constraints (formula-based)
  custom_constraints:
    - name: "throughput_per_lut_efficiency"
      description: "Throughput per LUT resource efficiency"
      formula: "throughput / lut_count"
      operator: ">"
      value: 0.5
      type: "soft"
      weight: 1.0
    
    - name: "power_efficiency"
      description: "Performance per watt efficiency"
      formula: "throughput / power"
      operator: ">"
      value: 100.0
      type: "soft"
      weight: 0.8
    
    - name: "resource_balance"
      description: "Balanced resource utilization"
      formula: "abs(lut_utilization - dsp_utilization)"
      operator: "<"
      value: 0.3
      type: "soft"
      weight: 0.5

# Metric collection configuration
metrics_config:
  # Enhanced metric collection
  collect_intermediate_results: true
  export_for_research: true
  save_build_artifacts: true
  
  # Performance metrics to collect
  performance_metrics:
    - "throughput_ops_sec"
    - "throughput_inferences_sec"
    - "latency_ms"
    - "clock_frequency_mhz"
    - "fps_achieved"
    - "fps_efficiency"
  
  # Resource metrics to collect
  resource_metrics:
    - "lut_count"
    - "lut_utilization_percent"
    - "dsp_count"
    - "dsp_utilization_percent"
    - "bram_18k_count"
    - "bram_utilization_percent"
    - "estimated_power_w"
    - "static_power_w"
    - "dynamic_power_w"
  
  # Quality metrics to collect
  quality_metrics:
    - "model_accuracy"
    - "verification_passed"
    - "max_error"
    - "mean_error"
  
  # Custom derived metrics
  custom_metrics:
    - name: "efficiency_score"
      formula: "(throughput * accuracy) / power"
      description: "Overall efficiency combining performance, accuracy, and power"
    
    - name: "throughput_per_lut"
      formula: "throughput / lut_count"
      description: "Throughput efficiency per LUT resource"
    
    - name: "throughput_per_watt"
      formula: "throughput / power"
      description: "Power efficiency in operations per watt"
    
    - name: "resource_utilization_score"
      formula: "(lut_utilization + dsp_utilization + bram_utilization) / 3"
      description: "Average resource utilization across all types"
    
    - name: "target_achievement_ratio"
      formula: "fps_achieved / target_fps"
      description: "How well the design meets the target performance"

# Research integration configuration
research_config:
  # Design space exploration settings
  dse_enabled: true
  
  # Recommended sampling strategies
  recommended_strategies:
    - "latin_hypercube"
    - "random"
    - "grid"
  
  # External tool integration
  export_formats:
    - "json"
    - "csv"
    - "hdf5"
  
  # Optimization objectives for multi-objective DSE
  optimization_objectives:
    primary:
      - name: "throughput"
        direction: "maximize"
        weight: 1.0
    
    secondary:
      - name: "power_efficiency"
        direction: "maximize"
        weight: 0.8
      
      - name: "resource_utilization"
        direction: "minimize"
        weight: 0.6
  
  # Constraint handling for DSE
  constraint_handling:
    enforce_hard_constraints: true
    penalty_factor: 1000.0
    constraint_tolerance: 0.05

# Version and compatibility information
version: "2.0"
compatibility:
  brainsmith_version: ">=2.0.0"
  finn_version: ">=1.0.0"
  requires_features:
    - "design_space_exploration"
    - "comprehensive_metrics"
    - "external_tool_integration"

# Additional metadata for research
metadata:
  model_family: "transformer"
  use_cases:
    - "natural_language_processing"
    - "text_classification"
    - "language_modeling"
  
  typical_model_sizes:
    - "bert-tiny"
    - "bert-mini"
    - "bert-small"
    - "bert-base"
  
  research_applications:
    - "design_space_exploration"
    - "multi_objective_optimization"
    - "architecture_comparison"
    - "performance_modeling"
  
  citation_info:
    description: "BERT model compilation with extensible design space for FPGA acceleration research"
    reference: "Brainsmith Platform for FPGA Dataflow Accelerator Development"