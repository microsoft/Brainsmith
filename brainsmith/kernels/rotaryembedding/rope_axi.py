# Auto-generated by Brainsmith Kernel Integrator for rope_axi
# Generated from: /home/tafk/dev/brainsmith-3/brainsmith/kernels/rotaryembedding/hdl/rope_axi.sv

from qonnx.core.datatype import DataType

from brainsmith.core.finn.auto_hw_custom_op import AutoHWCustomOp
from brainsmith.core.dataflow import (
    KernelDefinition,
    InputDefinition,
    OutputDefinition,
    RelationType
)
from brainsmith.core.dataflow.constraint_types import DatatypeConstraintGroup


class RopeAxi(AutoHWCustomOp):
    """
    Auto-generated HWCustomOp for rope_axi kernel.
    
    Generated from RTL: /home/tafk/dev/brainsmith-3/brainsmith/kernels/rotaryembedding/hdl/rope_axi.sv
    Uses direct KernelMetadata access with AutoHWCustomOp base class.
    """
    
    def __init__(self, onnx_node, **kwargs):
        """Initialize RopeAxi with KernelDefinition."""
        kernel_def = self._create_kernel_definition()
        super().__init__(onnx_node, kernel_def, **kwargs)
    
    def get_nodeattr_types(self):
        """
        Define all node attributes for rope_axi.
        """
        attrs = super().get_nodeattr_types()
        
        kernel_attrs = {
            "inputDataType": ('s', True, ""),
            "outputDataType": ('s', True, ""),
            ":": ('i', True, 0),
            "SIMD": ('i', True, 0),
            # Backend selection attribute
            "preferred_impl_style": ('s', False, "rtl"),
        }
        attrs.update(kernel_attrs)
        
        return attrs
    
    def _create_kernel_definition(self) -> KernelDefinition:
        """
        Create KernelDefinition for rope_axi.
        
        Creates KernelDefinition using direct metadata access.
        """
        kernel_def = KernelDefinition("rope_axi")
        
        # All input definitions (regular inputs and AXI-Stream weights)
        input_def = InputDefinition(
            name="input",
            datatype_constraints=[
                DatatypeConstraintGroup(
                    base_type="INT",
                    min_width=1,
                    max_width=32
                ),
            ],
            block_tiling=[":", ":"],
            stream_tiling=["SIMD"],
        )
        kernel_def.add_input(input_def)
        
        # AXI-Lite weight interfaces as input definitions
        
        # Output definitions
        output_def = OutputDefinition(
            name="output",
            datatype_constraints=[
            ],
        )
        kernel_def.add_output(output_def)
        
        # Add relationships (if they exist on KernelMetadata)
        
        return kernel_def

    ############################################################################
    # ======================= MANUALLY IMPLEMENT FUNCTIONS BELOW ===============
    # Add custom helper methods, execution logic, and resource estimation logic
    # here. This section is intentionally left for manual implementation.
    ############################################################################
        
    def execute_node(self, context, graph):
        """
        Execute the hardware kernel in simulation.
        
        TODO: Implement this method for your specific kernel.
        This should handle both 'cppsim' and 'rtlsim' execution modes.
        
        For reference implementation, see:
        # TAFK TODO
        """
        raise NotImplementedError(
            f"execute_node() not implemented for {self.__class__.__name__}. "
            "Please implement this method to support simulation."
        )
    
    def bram_estimation(self):
        """
        Estimate BRAM usage for this kernel.
        
        TODO: Implement based on your kernel's memory requirements.
        Return the number of BRAM blocks needed.
        
        For kernels without memory requirements, return 0.
        For kernels with weights/parameters, calculate based on:
        - Weight tensor dimensions
        - Parallelism factors (PE)
        - Memory packing efficiency
        """
        raise NotImplementedError(
            f"bram_estimation() not implemented for {self.__class__.__name__}. "
            "Please implement this method to provide resource estimates."
        )
    
    def uram_estimation(self):
        """
        Estimate URAM usage for this kernel.
        
        TODO: Implement based on your kernel's memory requirements.
        Return the number of URAM blocks needed.
        
        For kernels without memory requirements, return 0.
        For kernels with large weight tensors, consider URAM usage.
        """
        raise NotImplementedError(
            f"uram_estimation() not implemented for {self.__class__.__name__}. "
            "Please implement this method to provide resource estimates."
        )
    
    def lut_estimation(self):
        """
        Estimate LUT usage for this kernel.
        
        TODO: Implement based on your kernel's logic requirements.
        Return the number of LUTs needed.
        
        Consider:
        - Computational complexity
        - Data path width
        - Control logic overhead
        """
        raise NotImplementedError(
            f"lut_estimation() not implemented for {self.__class__.__name__}. "
            "Please implement this method to provide resource estimates."
        )


# Kernel metadata for reference
"""
rope_axi Kernel Specification:

Core Functionality:
- Module: rope_axi
- Source: /home/tafk/dev/brainsmith-3/brainsmith/kernels/rotaryembedding/hdl/rope_axi.sv

Interfaces:
- Input: input (RTL: s_axis)
- Output: output (RTL: m_axis)

Interface Attributes:
- inputDataType: Input interface datatype selection
- outputDataType: Output interface datatype selection  

Shape Parameters:
BDIM Parameters:
- :: int (block dimension parameter)
SDIM Parameters:
- SIMD: int (stream dimension parameter)

"""