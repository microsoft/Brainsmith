# Auto-generated by Brainsmith Kernel Integrator for {{ kernel_metadata.name }}
# Generated from: {{ kernel_metadata.source_file }}

from qonnx.core.datatype import DataType

from brainsmith.core.finn.auto_hw_custom_op import AutoHWCustomOp
from brainsmith.core.dataflow import (
    KernelDefinition,
    InputDefinition,
    OutputDefinition,
    RelationType
)
from brainsmith.core.dataflow.qonnx_types import DatatypeConstraintGroup


class {{ kernel_metadata.class_name }}(AutoHWCustomOp):
    """
    Auto-generated HWCustomOp for {{ kernel_metadata.name }} kernel.
    
    Generated from RTL: {{ kernel_metadata.source_file }}
    Uses direct KernelMetadata access with AutoHWCustomOp base class.
    """
    
    def __init__(self, onnx_node, **kwargs):
        """Initialize {{ kernel_metadata.class_name }} with KernelDefinition."""
        kernel_def = self._create_kernel_definition()
        super().__init__(onnx_node, kernel_def, **kwargs)
    
    def get_nodeattr_types(self):
        """
        Define all node attributes for {{ kernel_metadata.name }}.
        """
        attrs = super().get_nodeattr_types()
        
        kernel_attrs = {
        {% for name, (type_char, required, default) in kernel_metadata.get_nodeattr_types().items() %}
            "{{ name }}": ('{{ type_char }}', {{ required }}, {% if default is string %}"{{ default }}"{% elif default is none %}None{% else %}{{ default }}{% endif %}),
        {% endfor %}
            # Backend selection attribute
            "preferred_impl_style": ('s', False, "rtl"),
        }
        attrs.update(kernel_attrs)
        
        return attrs
    
    def _create_kernel_definition(self) -> KernelDefinition:
        """
        Create KernelDefinition for {{ kernel_metadata.name }}.
        
        Creates KernelDefinition using direct metadata access.
        """
        kernel_def = KernelDefinition("{{ kernel_metadata.name }}")
        
        # All input definitions (regular inputs and AXI-Stream weights)
        {% for interface in kernel_metadata.inputs %}
        input_def = InputDefinition(
            name="{{ interface.compiler_name }}",
            datatype_constraints=[
                {% for constraint in interface.datatype_constraints %}
                DatatypeConstraintGroup(
                    base_type="{{ constraint.base_type }}",
                    min_width={{ constraint.min_width }},
                    max_width={{ constraint.max_width }}
                ),
                {% endfor %}
            ],
            {% if interface.bdim_shape %}
            block_tiling={{ interface.bdim_shape | tojson }},
            {% endif %}
            {% if interface.sdim_shape %}
            stream_tiling={{ interface.sdim_shape | tojson }},
            {% endif %}
            {% if interface.is_weight %}
            is_weight=True
            {% endif %}
        )
        kernel_def.add_input(input_def)
        {% endfor %}
        
        # AXI-Lite weight interfaces as input definitions
        {% for interface in kernel_metadata.config %}
        {% if interface.is_weight %}
        input_def = InputDefinition(
            name="{{ interface.compiler_name }}",
            datatype_constraints=[
                {% for constraint in interface.datatype_constraints %}
                DatatypeConstraintGroup(
                    base_type="{{ constraint.base_type }}",
                    min_width={{ constraint.min_width }},
                    max_width={{ constraint.max_width }}
                ),
                {% endfor %}
            ],
            {% if interface.bdim_shape %}
            block_tiling={{ interface.bdim_shape | tojson }},
            {% endif %}
            {% if interface.sdim_shape %}
            stream_tiling={{ interface.sdim_shape | tojson }},
            {% endif %}
            is_weight=True
        )
        kernel_def.add_input(input_def)
        {% endif %}
        {% endfor %}
        
        # Output definitions
        {% for interface in kernel_metadata.outputs %}
        output_def = OutputDefinition(
            name="{{ interface.compiler_name }}",
            datatype_constraints=[
                {% for constraint in interface.datatype_constraints %}
                DatatypeConstraintGroup(
                    base_type="{{ constraint.base_type }}",
                    min_width={{ constraint.min_width }},
                    max_width={{ constraint.max_width }}
                ),
                {% endfor %}
            ],
            {% if interface.bdim_shape %}
            block_tiling={{ interface.bdim_shape | tojson }}
            {% endif %}
        )
        kernel_def.add_output(output_def)
        {% endfor %}
        
        # Add relationships (if they exist on KernelMetadata)
        {% if kernel_metadata.relationships is defined %}
        {% for rel in kernel_metadata.relationships %}
        kernel_def.add_relationship(
            source_name="{{ rel.source_interface }}",
            target_name="{{ rel.target_interface }}",
            relationship_type=RelationType.{{ rel.relation.name }},
            {% if rel.source_dim is not none %}source_dim={{ rel.source_dim }},{% endif %}
            {% if rel.target_dim is not none %}target_dim={{ rel.target_dim }},{% endif %}
            {% if rel.factor is not none %}factor={{ rel.factor }},{% endif %}
            {% if rel.dependency_type %}dependency_type="{{ rel.dependency_type }}"{% endif %}
        )
        {% endfor %}
        {% endif %}
        
        return kernel_def

    ############################################################################
    # ======================= MANUALLY IMPLEMENT FUNCTIONS BELOW ===============
    # Add custom helper methods, execution logic, and resource estimation logic
    # here. This section is intentionally left for manual implementation.
    ############################################################################
        
    def execute_node(self, context, graph):
        """
        Execute the hardware kernel in simulation.
        
        TODO: Implement this method for your specific kernel.
        This should handle both 'cppsim' and 'rtlsim' execution modes.
        
        For reference implementation, see:
        # TAFK TODO
        """
        raise NotImplementedError(
            f"execute_node() not implemented for {self.__class__.__name__}. "
            "Please implement this method to support simulation."
        )
    
    def bram_estimation(self):
        """
        Estimate BRAM usage for this kernel.
        
        TODO: Implement based on your kernel's memory requirements.
        Return the number of BRAM blocks needed.
        
        For kernels without memory requirements, return 0.
        For kernels with weights/parameters, calculate based on:
        - Weight tensor dimensions
        - Parallelism factors (PE)
        - Memory packing efficiency
        """
        raise NotImplementedError(
            f"bram_estimation() not implemented for {self.__class__.__name__}. "
            "Please implement this method to provide resource estimates."
        )
    
    def uram_estimation(self):
        """
        Estimate URAM usage for this kernel.
        
        TODO: Implement based on your kernel's memory requirements.
        Return the number of URAM blocks needed.
        
        For kernels without memory requirements, return 0.
        For kernels with large weight tensors, consider URAM usage.
        """
        raise NotImplementedError(
            f"uram_estimation() not implemented for {self.__class__.__name__}. "
            "Please implement this method to provide resource estimates."
        )
    
    def lut_estimation(self):
        """
        Estimate LUT usage for this kernel.
        
        TODO: Implement based on your kernel's logic requirements.
        Return the number of LUTs needed.
        
        Consider:
        - Computational complexity
        - Data path width
        - Control logic overhead
        """
        raise NotImplementedError(
            f"lut_estimation() not implemented for {self.__class__.__name__}. "
            "Please implement this method to provide resource estimates."
        )


# Kernel metadata for reference
"""
{{ kernel_metadata.name }} Kernel Specification:

Core Functionality:
- Module: {{ kernel_metadata.name }}
- Source: {{ kernel_metadata.source_file }}

Interfaces:
{% for interface in kernel_metadata.inputs %}
- Input: {{ interface.compiler_name }}{% if interface.is_weight %} (weight){% endif %} (RTL: {{ interface.name }})
{% endfor %}
{% for interface in kernel_metadata.outputs %}
- Output: {{ interface.compiler_name }} (RTL: {{ interface.name }})
{% endfor %}

Interface Attributes:
{% for interface in kernel_metadata.inputs %}
- {{ interface.compiler_name }}DataType: Input interface datatype selection
{% endfor %}
{% for interface in kernel_metadata.outputs %}
- {{ interface.compiler_name }}DataType: Output interface datatype selection  
{% endfor %}
{% for interface in kernel_metadata.config %}
{% if interface.is_weight %}
- {{ interface.compiler_name }}DataType: Weight interface datatype selection (AXI-Lite)
{% else %}
- {{ interface.compiler_name }}DataType: Config interface datatype selection
{% endif %}
{% endfor %}

Shape Parameters:
{% if kernel_metadata.has_bdim_params %}
BDIM Parameters:
{% for param_name in kernel_metadata.get_all_bdim_params() %}
- {{ param_name }}: int (block dimension parameter)
{% endfor %}
{% endif %}
{% if kernel_metadata.has_sdim_params %}
SDIM Parameters:
{% for param_name in kernel_metadata.get_all_sdim_params() %}
- {{ param_name }}: int (stream dimension parameter)
{% endfor %}
{% endif %}

{% if kernel_metadata.config %}
Configuration:
- runtime_writeable_weights: bool = True (supports runtime weight updates)
{% endif %}
"""