{# Jinja2 template for HWCustomOp #}
############################################################################
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.
#
# @author       Thomas Keller <thomaskeller@microsoft.com>
############################################################################

# Auto-generated by Brainsmith Hardware Kernel Generator
# Date: {{ generation_timestamp if generation_timestamp else "Not Specified" }}
# Source RTL Kernel: {{ hw_kernel.name if hw_kernel else "Unknown" }}

from finn.custom_op.fpgadataflow.hwcustomop import HWCustomOp
from qonnx.core.datatype import DataType # Assuming needed for placeholders
import warnings # Assuming needed for placeholders
import numpy as np # Assuming needed for placeholders

# Note: This is a generated file. Please use caution when editing manually.
# Consider using the generator tool for modifications.

class {{ class_name }}(HWCustomOp):
    """
    Abstraction layer for the hardware implementation of the '{{ hw_kernel.name }}' kernel.

    This class is automatically generated by the Brainsmith Hardware Kernel Generator.
    It provides the necessary interface for the FINN compiler to interact with
    the custom RTL kernel.
    """

    def __init__(self, onnx_node, **kwargs):
        super().__init__(onnx_node, **kwargs)

    def get_nodeattr_types(self):
        """Return a dictionary describing node attributes specific to this HWCustomOp."""
        my_attrs = {
            # Attributes derived from RTL parameters:
            {% for name, (type, required, default, allowed_values) in node_attributes.items() %}
            "{{ name }}": ("{{ type }}", {{ required }}, {{ default | repr if default is not none else 'None' }}{% if allowed_values %}, {{ allowed_values | repr }}{% endif %}),
            {% endfor %}
            # Future: Add attributes derived from interfaces (inputDataType, etc.) here
        }
        # Merge with attributes from the base class
        my_attrs.update(super().get_nodeattr_types())
        return my_attrs

    # --- Placeholder Methods ---
    # The following methods are placeholders generated by the tool.
    # They need to be implemented based on the specific functionality and
    # interface of the '{{ hw_kernel.name }}' RTL kernel.
    {% for method_name, method_code in placeholder_methods.items() %}
    {{ method_code | indent(4) }}
    {% endfor %}

    # --- Potentially needed for RTLBackend subclass ---
    # These might be implemented in a separate RTLBackend class or directly here
    # if the generated class will also inherit from RTLBackend.

    # def get_verilog_top_module_name(self):
    #      """Return the name of the Verilog top module."""
    #      # Usually derived from the kernel name or a specific attribute
    #      # Example: return self.get_nodeattr("gen_top_module")
    #      # Example: return f"{self.hw_kernel.name}_wrapper" # Assuming a wrapper exists
    #      raise NotImplementedError(f"get_verilog_top_module_name needs implementation for {self.onnx_node.name}")

    # def get_verilog_top_module_intf_names(self):
    #      """Return a dictionary defining the interface names for the Verilog module."""
    #      # Maps standard FINN interface types (axilite, axis_in, axis_out, ...)
    #      # to the actual signal prefixes/names used in the RTL wrapper.
    #      intf_names = super().get_verilog_top_module_intf_names()
    #      # Example: Add AXI-Lite if present
    #      # from .data import InterfaceType # Assuming InterfaceType is accessible
    #      # if any(iface.type == InterfaceType.AXI_LITE for iface in self.hw_kernel.interfaces.values()):
    #      #     intf_names["axilite"] = [name for name, iface in self.hw_kernel.interfaces.items() if iface.type == InterfaceType.AXI_LITE]
    #      # Example: Map AXI-Stream interfaces (assumes naming convention like s_axis_0, m_axis_0)
    #      # axis_in_if_names = sorted([name for name, iface in self.hw_kernel.interfaces.items() if iface.type == InterfaceType.AXI_STREAM and name.startswith('s_axis')])
    #      # axis_out_if_names = sorted([name for name, iface in self.hw_kernel.interfaces.items() if iface.type == InterfaceType.AXI_STREAM and name.startswith('m_axis')])
    #      # if axis_in_if_names:
    #      #    intf_names["axis_in"] = axis_in_if_names
    #      # if axis_out_if_names:
    #      #    intf_names["axis_out"] = axis_out_if_names
    #      raise NotImplementedError(f"get_verilog_top_module_intf_names needs implementation for {self.onnx_node.name}")

    # def generate_params(self, model, path):
    #      """Generate hardware parameters and memory initializers."""
    #      # Creates the .dat files for memory initialization if needed
    #      raise NotImplementedError(f"generate_params needs implementation for {self.onnx_node.name}")

    # def code_generation_ipgen(self, model, fpgapart, clk):
    #      """Generate the IP package for Vivado."""
    #      # Usually involves copying RTL files and the generated wrapper
    #      raise NotImplementedError(f"code_generation_ipgen needs implementation for {self.onnx_node.name}")

    # def code_generation_ipi(self):
    #      """Generate the TCL commands for Vivado IPI block design."""
    #      # Creates TCL commands to instantiate the generated IP
    #      raise NotImplementedError(f"code_generation_ipi needs implementation for {self.onnx_node.name}")

# Example instantiation (for reference, actual instantiation done by FINN)
# if __name__ == "__main__":
#     # This is just illustrative; HWCustomOp nodes are created within a FINN model
#     from qonnx.core.modelwrapper import ModelWrapper
#     import onnx.helper as oh
#     # Dummy node attributes matching the generated get_nodeattr_types
#     node_attributes = {
#         {% for name, (type, required, default, allowed_values) in node_attributes.items() -%}
#         "{{ name }}": {{ default | repr if default is not none else 'None' }}, # Example value
#         {% endfor -%}
#         "backend": "fpgadataflow",
#         "preferred_impl_style": "rtl", # Assuming RTL
#         # Add other necessary attributes like domain, op_type
#     }
#     # Create a dummy ONNX node
#     dummy_onnx_node = oh.make_node(
#         "{{ class_name }}", # op_type should match the class name or a registered op_type
#         inputs=["input_tensor"], # Example input name
#         outputs=["output_tensor"], # Example output name
#         name="my_{{ hw_kernel.name }}_instance",
#         domain="finn.custom_op.fpgadataflow", # Or appropriate domain
#         **node_attributes
#     )
#     # Instantiation (typically done by FINN's infrastructure)
#     # instance = {{ class_name }}(dummy_onnx_node)
#     # print(f"Illustrative instance created for {instance.onnx_node.name}")
#     # print(f"Node Attributes: {instance.get_nodeattr_types()}")
