{#-
AutoHWCustomOp Subclass Template

This template generates AutoHWCustomOp subclasses that:
1. Create simplified KernelDefinition with interface definitions
2. Generate explicit get_nodeattr_types() method for FINN integration
3. Inherit all FINN method implementations from AutoHWCustomOp
4. Only implement kernel-specific runtime extraction methods

Key features:
- Explicit, human-readable node attribute definitions
- No runtime CodegenBinding dependencies
- Clean separation of concerns
- Compile-time parameter binding resolution
-#}
############################################################################
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.
#
# Auto-generated HWCustomOp for {{ kernel_name }}
# Generated from: {{ source_file }}
# Generation timestamp: {{ generation_timestamp }}
#
# This HWCustomOp uses the modern AutoHWCustomOp base class with explicit
# parameter definitions and no runtime CodegenBinding dependencies.
############################################################################

from typing import List, Dict, Tuple, Any
import numpy as np
from qonnx.core.datatype import DataType

from brainsmith.core.finn.auto_hw_custom_op import AutoHWCustomOp
from brainsmith.core.dataflow import (
    KernelDefinition,
    InputDefinition,
    OutputDefinition,
    RelationType
)
from brainsmith.core.dataflow.qonnx_types import DatatypeConstraintGroup


class {{ class_name }}(AutoHWCustomOp):
    """
    Auto-generated HWCustomOp for {{ kernel_name }} kernel.
    
    Generated from RTL: {{ source_file }}
    Uses AutoHWCustomOp for automatic FINN method implementation.
    """
    
    def __init__(self, onnx_node, **kwargs):
        """Initialize {{ class_name }} with KernelDefinition."""
        kernel_def = self._create_kernel_definition()
        super().__init__(onnx_node, kernel_def, **kwargs)
        
        # Set kernel-specific attributes
        self.kernel_name = "{{ kernel_name }}"
        self.rtl_source = "{{ source_file }}"
    
    def get_nodeattr_types(self):
        """Define interface datatypes and BDIM/SDIM parameters from SHAPE pragmas."""
        return {
            # Interface datatype attributes (required by FINN)
            {% for attr in explicit_datatype_attrs %}
            "{{ attr.name }}": {{ attr.attr_spec | replace('null', 'None') | replace('true', 'True') | replace('false', 'False') }},
            {% endfor %}
            
            # BDIM/SDIM parameters from SHAPE pragmas
            {% for param in shape_nodeattrs %}
            "{{ param.name }}": ('i', False, 1),  # {{ param.source_comment }}
            {% endfor %}
            
            # Optional hardware optimization hints
            {% if has_weights %}
            "ram_style": ('s', False, 'auto', {'auto', 'block', 'distributed', 'ultra'}),
            {% endif %}
        }
    
    def _create_kernel_definition(self) -> KernelDefinition:
        """Create simplified KernelDefinition with interface definitions only."""
        kernel_def = KernelDefinition(name="{{ kernel_name }}")
        
        # Add input definitions
        {% for interface in input_interfaces %}
        input_def = InputDefinition(
            name="{{ interface.name }}",
            datatype_constraints=[
                {% for constraint in interface.datatype_constraints %}
                DatatypeConstraintGroup(
                    base_type="{{ constraint.base_type }}",
                    min_width={{ constraint.min_width }},
                    max_width={{ constraint.max_width }}
                ),
                {% endfor %}
            ],
            {% if interface.bdim_shape %}
            block_tiling={{ interface.bdim_shape | tojson }},
            {% endif %}
            {% if interface.sdim_shape %}
            stream_tiling={{ interface.sdim_shape | tojson }}
            {% endif %}
        )
        kernel_def.add_input(input_def)
        {% endfor %}
        
        # Add weight input definitions
        {% for interface in weight_interfaces %}
        weight_def = InputDefinition(
            name="{{ interface.name }}",
            datatype_constraints=[
                {% for constraint in interface.datatype_constraints %}
                DatatypeConstraintGroup(
                    base_type="{{ constraint.base_type }}",
                    min_width={{ constraint.min_width }},
                    max_width={{ constraint.max_width }}
                ),
                {% endfor %}
            ],
            {% if interface.bdim_shape %}
            block_tiling={{ interface.bdim_shape | tojson }},
            {% endif %}
            {% if interface.sdim_shape %}
            stream_tiling={{ interface.sdim_shape | tojson }},
            {% endif %}
            is_weight=True
        )
        kernel_def.add_input(weight_def)
        {% endfor %}
        
        # Add output definitions
        {% for interface in output_interfaces %}
        output_def = OutputDefinition(
            name="{{ interface.name }}",
            datatype_constraints=[
                {% for constraint in interface.datatype_constraints %}
                DatatypeConstraintGroup(
                    base_type="{{ constraint.base_type }}",
                    min_width={{ constraint.min_width }},
                    max_width={{ constraint.max_width }}
                ),
                {% endfor %}
            ],
            {% if interface.bdim_shape %}
            block_tiling={{ interface.bdim_shape | tojson }}
            {% endif %}
        )
        kernel_def.add_output(output_def)
        {% endfor %}
        
        # Add relationships
        {% for rel in relationships %}
        kernel_def.add_relationship(
            source_name="{{ rel.source_interface }}",
            target_name="{{ rel.target_interface }}",
            relationship_type=RelationType.{{ rel.relation.name }},
            {% if rel.source_dim is not none %}source_dim={{ rel.source_dim }},{% endif %}
            {% if rel.target_dim is not none %}target_dim={{ rel.target_dim }},{% endif %}
            {% if rel.factor is not none %}factor={{ rel.factor }},{% endif %}
            {% if rel.dependency_type %}dependency_type="{{ rel.dependency_type }}"{% endif %}
        )
        {% endfor %}
        return kernel_def
    
    def _extract_input_specs(self) -> Dict[str, Tuple[Tuple[int, ...], DataType]]:
        """
        Extract input specifications from ONNX context.
        
        Returns:
            Dictionary mapping input names to (shape, datatype) tuples
        """
        specs = {}
        
        {% for i, interface in enumerate(input_interfaces + weight_interfaces) %}
        # {{ interface.name }} interface
        # Get shape from ONNX graph context - input shapes must be inferred from graph
        # For now, use a default shape that will be overridden by the ONNX graph
        input_shape_{{ i }} = [1, 64]  # Default shape - will be replaced by actual ONNX tensor shape
        input_dtype_{{ i }} = DataType[self.get_nodeattr("{{ interface.name }}DataType")]
        specs["{{ interface.name }}"] = (tuple(input_shape_{{ i }}), input_dtype_{{ i }})
        
        {% endfor %}
        return specs
    
    def _extract_output_specs(self) -> Dict[str, Tuple[Tuple[int, ...], DataType]]:
        """
        Extract output specifications from ONNX context.
        
        Returns:
            Dictionary mapping output names to (shape, datatype) tuples
        """
        specs = {}
        
        {% for i, interface in enumerate(output_interfaces) %}
        # {{ interface.name }} interface
        {% if kernel_type == 'threshold' %}
        # For thresholding, output shape equals input shape
        output_shape_{{ i }} = [1, 64]  # Default - equals input shape for thresholding
        {% else %}
        # Derive output shape from kernel behavior
        output_shape_{{ i }} = [1, 64]  # Default shape - derived from kernel logic
        {% endif %}
        output_dtype_{{ i }} = DataType[self.get_nodeattr("{{ interface.name }}DataType")]
        specs["{{ interface.name }}"] = (tuple(output_shape_{{ i }}), output_dtype_{{ i }})
        
        {% endfor %}
        return specs
    
    {% if verification_required %}
    def verify_node(self) -> List[str]:
        """Verify kernel-specific constraints."""
        messages = super().verify_node()
        
        # Verify all required parameters are present
        {% for param in required_attributes %}
        if self.get_nodeattr("{{ param }}") is None:
            messages.append(f"âœ— Required parameter '{{ param }}' not specified")
        {% endfor %}
        
        # Additional {{ kernel_name }}-specific verification
        # TODO: Add kernel-specific constraint checks
        
        return messages
    {% endif %}


# Convenience function for FINN integration
def make_{{ kernel_name }}_node(inputs, outputs, **node_attrs):
    """
    Create {{ class_name }} ONNX node.
    
    Interface datatype attributes (required):
    {% for interface_attr in explicit_datatype_attrs %}
    - {{ interface_attr.name }}: str = "{{ interface_attr.default_datatype }}"
    {% endfor %}
    
    BDIM/SDIM parameters from SHAPE pragmas:
    {% for param in shape_nodeattrs %}
    - {{ param.name }}: int = 1  # {{ param.source_comment }}
    {% endfor %}
    
    {% if has_weights %}
    Hardware optimization hints:
    - ram_style: str = 'auto'
    {% endif %}
    """
    import onnx.helper
    
    # Ensure interface datatypes are specified
    {% for interface_attr in explicit_datatype_attrs %}
    if "{{ interface_attr.name }}" not in node_attrs:
        node_attrs["{{ interface_attr.name }}"] = "{{ interface_attr.default_datatype }}"
    {% endfor %}
    
    return onnx.helper.make_node(
        "{{ class_name }}",
        inputs=inputs,
        outputs=outputs,
        domain="finn.custom_op.fpgadataflow",
        **node_attrs
    )