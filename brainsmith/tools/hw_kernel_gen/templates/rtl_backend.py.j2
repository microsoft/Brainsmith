{#-
RTLBackend Template for HWKG

Generates minimal RTLBackend subclasses that inherit from AutoRTLBackend
and provide operation-specific customizations.
-#}
# Auto-generated by Brainsmith Hardware Kernel Generator
# Generated from: {{ source_file }}
# Date: {{ generation_timestamp }}

{% if base_kernel_class %}
from finn.custom_op.fpgadataflow.{{ base_kernel_class.lower() }} import {{ base_kernel_class }}
{% endif %}
from brainsmith.dataflow.core.auto_rtl_backend import AutoRTLBackend
{% if datatype_derivation_methods %}
from qonnx.core.datatype import DataType
{% endif %}
{% if complexity_level == "medium" and has_implementation_styles %}
from brainsmith.dataflow.core.auto_rtl_backend import ImplementationStyleMixin
{% endif %}
{% if complexity_level == "high" and has_advanced_memory %}
from brainsmith.dataflow.core.auto_rtl_backend import AdvancedMemoryMixin
{% endif %}
{% if has_dynamic_config %}
from brainsmith.dataflow.core.auto_rtl_backend import DynamicConfigMixin
{% endif %}


class {{ kernel_name }}_rtl({% if base_kernel_class %}{{ base_kernel_class }}, {% endif %}{% if complexity_level == "medium" and has_implementation_styles %}ImplementationStyleMixin, {% endif %}{% if complexity_level == "high" and has_advanced_memory %}AdvancedMemoryMixin, {% endif %}{% if has_dynamic_config %}DynamicConfigMixin, {% endif %}AutoRTLBackend):
    """RTL backend for {{ kernel_name }} operation.
    
    Auto-generated from SystemVerilog RTL analysis.
    {% if operation_description %}
    
    {{ operation_description }}
    {% endif %}
    """
    
    def __init__(self, onnx_node, **kwargs):
        super().__init__(onnx_node, **kwargs)
    
    @property
    def finn_rtllib_module(self) -> str:
        """Return finn-rtllib module name for this operation."""
        return "{{ finn_rtllib_module }}"
    
    def get_nodeattr_types(self):
        """Get node attribute types for RTLBackend (algorithm parameters only)."""
        my_attrs = {}
        
        # Only expose algorithm parameters (exposed parameters only)
{% for param in parameter_definitions %}
    {% if param.name in exposed_parameters %}
        {% if param.required %}
        # Algorithm parameter - required
        my_attrs["{{ param.name }}"] = ("i", True, {{ param.default_value if param.default_value is not none else "None" }})
        {% else %}
        # Algorithm parameter - optional with default
        my_attrs["{{ param.name }}"] = ("i", False, {{ param.default_value if param.default_value is not none else "1" }})
        {% endif %}
    {% endif %}
{% endfor %}
        
        # Merge with parent class attributes
{% if base_kernel_class %}
        my_attrs.update({{ base_kernel_class }}.get_nodeattr_types(self))
{% endif %}
        my_attrs.update(AutoRTLBackend.get_nodeattr_types(self))
        
        return my_attrs
    
    def prepare_codegen_rtl_values(self, model):
        """Prepare template variables for RTL code generation.
        
        All dictionary values produced in this function are to replace
        their key value(s) in the RTL template files following FINN's pattern.
        """
        code_gen_dict = {}
        
        # Basic module information
        code_gen_dict["$MODULE_NAME_AXI_WRAPPER$"] = [self.get_verilog_top_module_name()]
        code_gen_dict["$TOP_MODULE$"] = code_gen_dict["$MODULE_NAME_AXI_WRAPPER$"]
        
        # Standard stream width variables
        code_gen_dict["$IBITS$"] = [str(self.get_instream_width())]
        code_gen_dict["$OBITS$"] = [str(self.get_outstream_width())]
        
        # Algorithm parameters from node attributes
{% for param in parameter_definitions %}
    {% if param.name in exposed_parameters %}
        code_gen_dict["${{ param.name.upper() }}$"] = [str(self.get_nodeattr("{{ param.name }}"))]
    {% endif %}
{% endfor %}
        
        # Linked parameters from interface metadata (BDIM, SDIM, datatype)
        interface_metadata = self.get_interface_metadata()
        for interface in interface_metadata:
            # BDIM parameter linkage
            if hasattr(interface, 'bdim_param') and interface.bdim_param:
                bdim_value = self.get_nodeattr(interface.bdim_param) if interface.bdim_param in {{ exposed_parameters }} else None
                if bdim_value is not None:
                    code_gen_dict[f"${interface.bdim_param.upper()}$"] = [str(bdim_value)]
            
            # SDIM parameter linkage  
            if hasattr(interface, 'sdim_param') and interface.sdim_param:
                sdim_value = self.get_nodeattr(interface.sdim_param) if interface.sdim_param in {{ exposed_parameters }} else None
                if sdim_value is not None:
                    code_gen_dict[f"${interface.sdim_param.upper()}$"] = [str(sdim_value)]
            
            # Datatype parameter linkage
            if hasattr(interface, 'datatype_params') and interface.datatype_params:
                # Get interface-specific datatype using compiler_name (e.g., input0DataType, output0DataType)
                compiler_name = getattr(interface, 'compiler_name', interface.name)
                datatype_attr_name = f"{compiler_name}DataType"
                
                for prop_type, param_name in interface.datatype_params.items():
                    if prop_type == 'width':
                        # Get width from interface-specific datatype attribute
                        interface_dt = self.get_nodeattr(datatype_attr_name)
                        if interface_dt:
                            from qonnx.core.datatype import DataType
                            code_gen_dict[f"${param_name.upper()}$"] = [str(DataType[interface_dt].bitwidth())]
                    elif prop_type == 'signed':
                        # Get signed from interface-specific datatype attribute
                        interface_dt = self.get_nodeattr(datatype_attr_name)
                        if interface_dt:
                            from qonnx.core.datatype import DataType
                            code_gen_dict[f"${param_name.upper()}$"] = [str(1 if DataType[interface_dt].signed() else 0)]
        
        # Legacy datatype-linked parameters (for backward compatibility)
{% for param_name in datatype_linked_params %}
    {% if param_name == "WI" %}
        # Input width from input datatype
        code_gen_dict["$WI$"] = [str(self.get_input_datatype().bitwidth())]
    {% elif param_name == "SIGNED" %}
        # Input signedness
        code_gen_dict["$SIGNED$"] = [str(1 if self.get_input_datatype().signed() else 0)]
    {% elif param_name == "FPARG" %}
        # Floating point argument (0=integer, 1=float)
        code_gen_dict["$FPARG$"] = [str(0 if self.get_input_datatype().is_integer() else 1)]
    {% elif param_name == "O_BITS" %}
        # Output bits calculation depends on operation specifics
        output_bitwidth = self.get_output_datatype().bitwidth()
        code_gen_dict["$O_BITS$"] = [str(output_bitwidth)]
    {% elif param_name == "BIAS" %}
        # Bias value if available from attributes
        bias = self.get_nodeattr("bias") if hasattr(self, "get_nodeattr") and "bias" in [attr for attr in dir(self) if "nodeattr" in attr] else 0
        code_gen_dict["$BIAS$"] = [str(bias)]
    {% elif param_name == "WT" or param_name == "WEIGHT_WIDTH" %}
        # Weight width from weight interface (if exists)
        weight_interfaces = [iface for iface in self.get_input_interfaces() if "weight" in iface.name.lower()]
        if weight_interfaces:
            code_gen_dict["$WT$"] = [str(self.get_input_datatype(len(self.get_input_interfaces()) - len(weight_interfaces)).bitwidth())]
        else:
            code_gen_dict["$WT$"] = ["8"]  # Default weight width
    {% elif param_name == "PE" %}
        # Processing elements
        pe = self.get_nodeattr("PE") if "PE" in str(self.get_nodeattr_types()) else 1
        code_gen_dict["$PE$"] = [str(pe)]
    {% elif param_name == "C" or param_name == "CHANNELS" %}
        # Number of channels
        channels = self.get_nodeattr("NumChannels") if "NumChannels" in str(self.get_nodeattr_types()) else 1
        code_gen_dict["$C$"] = [str(channels)]
    {% elif param_name == "N" %}
        # Output precision
        code_gen_dict["$N$"] = [str(self.get_output_datatype().bitwidth())]
    {% else %}
        # Generic datatype-linked parameter
        code_gen_dict["${{ param_name.upper() }}$"] = [str(self.get_nodeattr("{{ param_name }}") if "{{ param_name }}" in str(self.get_nodeattr_types()) else 1)]
    {% endif %}
{% endfor %}
        
        return code_gen_dict
    
    def get_supporting_rtl_files(self) -> list:
        """Get list of supporting RTL files to include."""
        return [
{% for file_name in supporting_rtl_files %}
            "{{ file_name }}",
{% endfor %}
        ]
{% if has_custom_execution %}
    
    def execute_node(self, context, graph):
        """Custom execution handling for {{ kernel_name }}."""
        mode = self.get_nodeattr("exec_mode")
        if mode == "cppsim":
{% if base_kernel_class %}
            {{ base_kernel_class }}.execute_node(self, context, graph)
{% else %}
            # Custom cppsim implementation would go here
            super().execute_node(context, graph)
{% endif %}
        elif mode == "rtlsim":
            # Custom rtlsim implementation for {{ kernel_name }}
            code_gen_dir = self.get_nodeattr("code_gen_dir_ipgen")
            
            # Input processing
            node = self.onnx_node
            for in_ind, inputs in enumerate(node.input):
                # Operation-specific input processing
                pass
            
            # RTL simulation
            sim = self.get_rtlsim()
            self.reset_rtlsim(sim)
            
            # Operation-specific simulation logic would go here
            
            self.close_rtlsim(sim)
        else:
            raise Exception(f"Invalid exec_mode '{mode}'. Must be 'cppsim' or 'rtlsim'")
{% endif %}
    
    def lut_estimation(self) -> int:
        """Estimate LUT usage for {{ kernel_name }}."""
        # TODO: Implement operation-specific LUT estimation
        # For now, use base class conservative estimate
        return super().lut_estimation()
    
    def bram_estimation(self) -> int:
        """Estimate BRAM usage for {{ kernel_name }}."""
        # TODO: Implement operation-specific BRAM estimation
        # For now, use base class estimate
        return super().bram_estimation()
    
    def dsp_estimation(self, fpgapart) -> int:
        """Estimate DSP usage for {{ kernel_name }}."""
        # TODO: Implement operation-specific DSP estimation
        # For now, use base class estimate
        return super().dsp_estimation(fpgapart)
{% if has_implementation_styles %}
    
    def select_impl_style(self):
        """Select optimal implementation style for {{ kernel_name }}."""
        # Operation-specific implementation style selection logic
        current_style = self.get_nodeattr("impl_style")
        
        # Add operation-specific selection criteria here
        # Example: depth-based selection for FIFOs
        {% if kernel_name.lower().startswith('fifo') %}
        depth = self.get_nodeattr("depth")
        if depth > 1024:
            return "vivado"  # Use Vivado IP for large FIFOs
        {% endif %}
        
        return current_style
{% endif %}
{% if has_dynamic_config %}
    
    def get_dynamic_config(self):
        """Get dynamic configuration data for {{ kernel_name }}."""
        config = {}
        
        # Add operation-specific dynamic configuration
        # Example: runtime weight updates for convolution operations
        
        return config
{% endif %}