# Softmax

**Softmax activation over channel dimension.**

**Operation**: `exp(x_i) / sum(exp(x_j))`

**Namespace**: `brainsmith.kernels`

**Backends**: HLS

!!! info "Stub Page"
    This page will be expanded with full documentation.

## Summary

Computes softmax normalization across the channel axis (last dimension).

**Constraint**: Float32 inputs only

## API Reference

::: brainsmith.kernels.softmax.Softmax
    options:
      show_source: true
      heading_level: 3
