# ğŸš€ BERT Accelerator Demo - Powered by brainsmith.forge()

**See how one function call creates FPGA accelerators from BERT models!**

## 30-Second Quick Start

### Option 1: Using Docker (Recommended)

```bash
# From the brainsmith root directory
./run-docker.sh python demos/bert_new/end2end_bert.py --output-dir ./bert_demo_output
```

### Option 2: Direct Python (if environment is set up)

```bash
# From the brainsmith root directory
python demos/bert_new/end2end_bert.py --output-dir ./bert_demo_output
```

**What just happened?** You created a complete FPGA accelerator for BERT inference using the `bert_minimal` blueprint. No complex configuration, no hardware expertise required.

## ğŸ¯ What This Demo Shows

- **The Power of One Function**: `brainsmith.forge()` handles everything
- **Blueprint Magic**: YAML blueprints make optimization automatic
- **Model â†’ Accelerator**: Complete end-to-end transformation
- **FPGA Made Simple**: Hardware acceleration without the complexity

## âœ¨ Customization Options

```bash
# Custom BERT size
./run-docker.sh python demos/bert_new/end2end_bert.py \
    --output-dir ./large_bert \
    --hidden-size 512 \
    --num-layers 6

# Different FPGA board
./run-docker.sh python demos/bert_new/end2end_bert.py \
    --output-dir ./versal_bert \
    --board "Versal_VCK190"

# Longer sequences
./run-docker.sh python demos/bert_new/end2end_bert.py \
    --output-dir ./long_seq_bert \
    --sequence-length 512
```

## ğŸ‰ What You Get

After successful completion, your output directory contains:
- `bert_model.onnx` - Your generated BERT model
- `accelerator.zip` - Complete FPGA accelerator core
- `bert_accelerator_info.json` - Build information
- Performance metrics and resource utilization

## Expected Output

You should see:
```
ğŸš€ BERT Accelerator Demo - Powered by brainsmith.forge()
ğŸ“¦ Generating BERT model: 3 layers, 384D
âœ¨ Watch one function call create an FPGA accelerator!
BERT model generated: ./bert_demo_output/bert_model.onnx
ğŸ“‹ Using blueprint: [blueprint_path]
ğŸ¯ Target board: V80
ğŸš€ Generating BERT accelerator with brainsmith.forge()...
ğŸ“¦ Processing results...
ğŸ‰ SUCCESS! BERT accelerator generated!
ğŸ“ Your accelerator is ready in: ./bert_demo_output
âš¡ Throughput: [X] operations/second
ğŸ—ï¸  Resource usage: [Y]% LUTs
ğŸš€ That's it! One function call created your FPGA accelerator.
ğŸ¯ Model: BERT 3 layers, 384 hidden size
ğŸ’¡ Ready to deploy on V80
```

## ğŸ”§ Under the Hood

The demo uses modern BrainSmith architecture:
- **`brainsmith.forge()`** - Single function for complete workflow
- **Blueprint system** - YAML-driven optimization
- **Automatic parameter selection** - No manual tuning needed
- **Clean error handling** - Clear success/failure feedback

## ğŸ“ Files

- `end2end_bert.py` - Main demo (showcases forge() simplicity)
- `gen_initial_folding.py` - Legacy reference (preserved for experts)
- `Makefile` - Advanced build recipes (for power users)

## ğŸ”§ Troubleshooting

**Q: "ModuleNotFoundError: No module named 'brainsmith'"**
A: Use the Docker option - it has all dependencies pre-installed.

**Q: "Blueprint not found"**
A: Ensure you're running from the brainsmith root directory.

**Q: Demo takes a long time**
A: Normal! FPGA compilation can take 10-30 minutes depending on model size.

## ğŸ¯ The Big Picture

This demo proves that FPGA acceleration doesn't have to be complex:

**Before**: Weeks of manual optimization, complex toolchains, hardware expertise required

**After**: One function call, automatic optimization, accelerator ready to deploy

## Next Steps

- Try different BERT configurations
- Experiment with other FPGA boards
- Deploy your accelerator to actual hardware
- Explore the generated files to understand the output

---

**Ready to see the magic? Run the 30-second demo above! ğŸš€**