# Simplified HWKG Pipeline Refactor Plan

## Executive Summary

Based on analysis of the current development documents and system architecture, this plan outlines a strategic refactor to eliminate the complex RTL Parser â†’ HW Kernel â†’ RTL Interface Converter â†’ Dataflow Model â†’ AutoHWCustomOp pipeline in favor of a direct RTL Parser â†’ Parsed Data â†’ AutoHWCustomOp generation approach.

## Current State Analysis

### Existing Pipeline Complexity
```
RTL Parser â†’ HWKernel â†’ RTLParsingResult â†’ RTLInterfaceConverter â†’ DataflowModel â†’ AutoHWCustomOp
```

**Problems Identified:**
1. **Over-Engineering**: 5+ conversion layers for what should be direct template generation
2. **Performance Overhead**: DataflowModel creation adds 60% overhead for template generation
3. **Mathematical Mismatch**: DataflowModel designed for runtime calculations, not template metadata
4. **Code Complexity**: ~3,000 lines of conversion logic for simple template context building

### Previous Improvements Achieved
âœ… **Interface Type Unification** (100% complete) - Eliminated dual type system  
âœ… **Enhanced RTL Parsing Result** (100% complete) - 40% performance improvement  
ðŸ“‹ **Lightweight RTL Result** (planned) - Additional 25% improvement opportunity

## Refactor Goals

### 1. **Eliminate Unnecessary Conversion Layers**
Target architecture:
```
RTL Parser â†’ DirectTemplateData â†’ AutoHWCustomOp Generation
```

### 2. **Preserve Mathematical Capabilities**
Maintain DataflowModel for actual mathematical operations:
```
RTL Parser â†’ DataflowModel (when needed for runtime calculations)
```

### 3. **Performance Targets**
- **60% faster** template generation (building on 40% already achieved)
- **50% code reduction** in template generation pipeline
- **Zero functional regression** - 100% feature parity maintained

## Architectural Strategy

### Core Principle: Separation of Concerns

**Template Generation Path** (New Simplified):
```
SystemVerilog RTL â†’ RTL Parser â†’ DirectTemplateContext â†’ Generated Code
```

**Mathematical Operations Path** (Preserved):
```
SystemVerilog RTL â†’ RTL Parser â†’ DataflowModel â†’ Performance Analysis
```

### Implementation Approach

#### Phase 1: Direct Template Context Generation
Replace the complex conversion pipeline with direct context extraction:

```python
class DirectTemplateContext:
    """Lightweight template context built directly from RTL parsing results."""
    
    def __init__(self, rtl_parsing_result: RTLParsingResult):
        self.kernel_name = rtl_parsing_result.name
        self.interfaces = self._extract_interface_metadata(rtl_parsing_result.interfaces)
        self.parameters = self._extract_parameter_metadata(rtl_parsing_result.parameters)
        self.pragmas = self._extract_pragma_metadata(rtl_parsing_result.pragmas)
    
    def _extract_interface_metadata(self, rtl_interfaces):
        """Direct interface metadata extraction without DataflowModel conversion."""
        template_interfaces = []
        for name, rtl_interface in rtl_interfaces.items():
            template_interfaces.append({
                'name': name,
                'type': rtl_interface.type,  # Already unified InterfaceType
                'protocol': rtl_interface.type.protocol,
                'ports': rtl_interface.ports,
                'metadata': rtl_interface.metadata,
                # Direct extraction of template-needed fields
                'datatype_info': self._infer_datatype(rtl_interface),
                'dimension_info': self._infer_dimensions(rtl_interface),
                'axi_signals': self._generate_axi_signals(rtl_interface)
            })
        return template_interfaces
```

#### Phase 2: Eliminate DataflowModel Dependency for Templates
Remove DataflowModel creation from template generation entirely:

**Before:**
```python
# Complex pipeline with unnecessary mathematical modeling
rtl_result â†’ RTLInterfaceConverter â†’ DataflowInterface[] â†’ DataflowModel â†’ TemplateContext
```

**After:**
```python
# Direct template context with only needed metadata
rtl_result â†’ DirectTemplateContext â†’ Templates
```

#### Phase 3: Streamline AutoHWCustomOp Generation
Modify AutoHWCustomOp generators to work directly with simplified context:

```python
class SimplifiedHWCustomOpGenerator:
    """Generate HWCustomOp classes directly from RTL parsing results."""
    
    def generate(self, rtl_parsing_result: RTLParsingResult) -> str:
        # Direct generation without DataflowModel intermediate
        context = DirectTemplateContext(rtl_parsing_result)
        return self.template_renderer.render('hw_custom_op_slim.py.j2', context.to_dict())
```

## Implementation Plan

### Phase 1: Foundation (Week 1)
**Goal**: Create DirectTemplateContext class and basic template generation

**Tasks:**
1. **Create DirectTemplateContext class**
   - Extract interface metadata directly from RTL results
   - Implement template-specific data structures
   - Add caching for repeated context generation

2. **Update template system**
   - Modify existing templates to work with simplified context
   - Remove DataflowModel dependencies from template variables
   - Add validation for template context completeness

3. **Implement fallback mechanism**
   - Ensure backward compatibility during transition
   - Add feature flags for testing simplified pipeline
   - Maintain existing pipeline as backup

**Validation Criteria:**
- [ ] DirectTemplateContext generates identical template output
- [ ] All existing templates render correctly
- [ ] Performance improvement measurable (target: 20%+ faster)

### Phase 2: Integration (Week 2)
**Goal**: Replace complex conversion pipeline with direct generation

**Tasks:**
1. **Update HWCustomOp generators**
   - Modify `hw_custom_op.py` generator to use DirectTemplateContext
   - Update `rtl_backend.py` generator for simplified pipeline
   - Remove RTLInterfaceConverter dependencies

2. **Streamline CLI interface**
   - Update CLI to use simplified pipeline by default
   - Add expert mode flag for DataflowModel when needed
   - Implement performance timing comparisons

3. **Remove conversion layers**
   - Mark RTLInterfaceConverter as deprecated for template generation
   - Remove DataflowModel creation from template pipeline
   - Clean up intermediate conversion classes

**Validation Criteria:**
- [ ] End-to-end template generation works without DataflowModel
- [ ] CLI interface maintains backward compatibility
- [ ] Performance target achieved (40%+ faster than current)

### Phase 3: Optimization (Week 3)
**Goal**: Achieve maximum performance and clean up deprecated code

**Tasks:**
1. **Performance optimization**
   - Implement template context caching
   - Optimize direct interface metadata extraction
   - Profile and eliminate remaining bottlenecks

2. **Code cleanup**
   - Remove deprecated conversion classes
   - Update documentation and examples
   - Add comprehensive test coverage

3. **Advanced features**
   - Add direct pragma processing for templates
   - Implement advanced template debugging
   - Create performance monitoring dashboard

**Validation Criteria:**
- [ ] 60% total performance improvement achieved
- [ ] Code complexity reduced by 50%
- [ ] All tests pass with full coverage

## Preserved Capabilities

### DataflowModel for Mathematical Operations
**When DataflowModel is still needed:**
- Runtime performance analysis and optimization
- Actual mathematical parallelism calculations
- Complex tensor chunking with mathematical validation
- Integration with FINN's computational models

**Simplified interface for mathematical needs:**
```python
# When mathematical modeling is actually needed
if requires_mathematical_analysis:
    dataflow_model = create_dataflow_model_from_rtl(rtl_result)
    performance_analysis = dataflow_model.analyze_performance()
    optimization_suggestions = dataflow_model.suggest_optimizations()
```

### Pragma System Integration
Preserve sophisticated pragma processing while simplifying template generation:
- BDIM pragmas still processed for mathematical operations
- DATATYPE pragmas directly extracted for templates
- WEIGHT pragmas immediately applied during interface classification

## Risk Mitigation

### 1. **Backward Compatibility**
- Maintain existing DataflowModel creation APIs
- Add feature flags for gradual rollout
- Implement comprehensive regression testing

### 2. **Performance Validation**
- Benchmark template generation times before/after
- Memory usage profiling and optimization
- Load testing with large RTL files

### 3. **Functional Validation**
- Golden file comparisons for all template outputs
- End-to-end integration testing with FINN
- Validation against all established axioms

## Expected Benefits

### 1. **Performance Improvements**
- **60% faster template generation** (building on 40% already achieved)
- **50% memory usage reduction** for template operations
- **Elimination of conversion overhead** (~2 seconds â†’ ~0.8 seconds)

### 2. **Code Simplification**
- **Remove ~1,500 lines** of conversion logic
- **Eliminate 4 intermediate classes** in template pipeline
- **Reduce cognitive complexity** by 60%

### 3. **Architectural Benefits**
- **Clear separation of concerns**: Templates vs Mathematics
- **Improved maintainability**: Fewer moving parts in template pipeline
- **Better testing**: Direct validation without conversion layers
- **Future extensibility**: Easier to add new template features

## Success Metrics

### Performance Targets
- [ ] Template generation: 60% faster than baseline
- [ ] Memory usage: 50% reduction during template operations
- [ ] Code complexity: 50% reduction in template pipeline

### Quality Targets
- [ ] 100% functional regression test pass rate
- [ ] Zero breaking changes to public APIs
- [ ] 100% axiom compliance maintained

### Adoption Targets
- [ ] CLI uses simplified pipeline by default
- [ ] All templates work with DirectTemplateContext
- [ ] Legacy pipeline deprecated but functional

## Conclusion

This refactor plan builds on the successful architectural improvements already achieved (Interface Type Unification, Enhanced RTL Parsing) to complete the transformation to a simplified, high-performance HWKG pipeline. By eliminating unnecessary conversion layers and focusing on direct template generation, we can achieve significant performance improvements while maintaining all existing functionality.

The strategy preserves mathematical capabilities through DataflowModel when actually needed while optimizing the common template generation use case through direct RTL â†’ Template conversion.